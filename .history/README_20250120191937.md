Voici la version traduite en français tout en conservant les liens et les images :

```markdown
# LEAD-Bloc1-Netflix-Recommendation-Jedha
## ![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/f17d64a9-3922-4cee-87dc-9b881085659c) Moteur de recommandation Netflix ![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/f17d64a9-3922-4cee-87dc-9b881085659c)
![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/2f002cd8-a41b-4e93-a357-b8eba4d86e69)

Ce dépôt (disponible sur GitHub) / document Word (disponible sur Google Drive) contient toutes les ressources liées à la présentation du projet sur le moteur de recommandation Netflix.

## Ressources disponibles :

- Le diaporama de la présentation est accessible dans le fichier nommé **Présentation_Certification_Bloc_1_Netflix_reco_en.pptx**.  
- Des ressources supplémentaires, y compris le modèle et les données d’entraînement, sont disponibles à ce lien : [Google Drive](https://drive.google.com/drive/folders/14qz8C2JKb7AuaLz6VbQjgEoHbhNFNw5S?usp=drive_link).  
- Le sujet du projet est accessible ici : [Jedha Final Projects](https://app.jedha.co/course/final-projects-l/netflix-automation-engine-l).  

Une description du contenu et des objectifs de chaque dossier dans ce dépôt est fournie ci-dessous.  
Pour toute question ou information complémentaire, veuillez contacter le propriétaire du dépôt sur GitHub : **billel0912** (billel_abbas@yahoo.fr).

---

## ![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/54ed3921-f6f6-4603-92b7-89904323f64d) Prétraitement des données et Entraînement du modèle : ![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/3b255f3b-1bc7-4eb1-9c02-512b41a4839b)

Ce répertoire, nommé **Preprocessing_Netflix**, contient :  
- **data_preprocessing.ipynb** : Un script qui effectue l'intégration des données depuis Kaggle et construit l'ensemble de données d'entraînement pour le modèle de recommandation.  
- Les données brutes sont disponibles ici : [Kaggle Netflix Dataset](https://www.kaggle.com/code/laowingkin/netflix-movie-recommendation).  

Le dossier **model** contient :  
- **model.pkl** : Une version sérialisée du modèle entraîné, utilisée pour générer des prédictions de films.  

Les fichiers de sortie incluent :  
- **data_cleaned.csv**, **data_reco.csv**, et **model.pkl**, disponibles sur Google Drive.

---

## Dossiers Airflow, Kafka et FASTAPI :
### Airflow
- **airflow.cfg** : Fichier de configuration pour Apache Airflow, utilisé pour créer, planifier et surveiller les workflows.  
- **airflow.db** : Base de données SQLite utilisée par Airflow. Il est conseillé d'utiliser PostgreSQL ou MySQL pour la production.  
- **dags** : Contient les DAGs (Directed Acyclic Graphs) Airflow.

Dans ce dossier **dags**, nous trouvons :  
- **Script “dag.py”** : Définit un DAG dans Apache Airflow avec trois tâches principales (**run_start**, **run_all**, et **run_end**). La tâche **run_all** exécute les scripts suivants : **app.py** (FastAPI), **producer.py**, et **consumer.py**.  

### FASTAPI
Le dossier **FASTAPI** contient :  
- **app.py** : Une application FastAPI fournissant une API pour générer des recommandations de films.  
  - Endpoint **/** : Renvoie un message simple "Hello world!".  
  - Endpoint **/suggested_movies** : Renvoie les 10 meilleurs films recommandés pour un utilisateur donné.  
- **data_reco.csv** : Contient les films et leurs scores estimés.  
- **model.pkl** : Modèle de prédiction.

### Kafka
Dans le dossier **Project_Final_Kafka**, nous trouvons :  
1. **ccloud_lib.py** : Fournit des fonctions pour interagir avec Confluent Cloud.  
2. **producer.py** : Envoie des données de l'API vers un topic Kafka sous forme de JSON.  
3. **consumer.py** : Consomme les données Kafka et utilise FastAPI pour générer des recommandations, qui sont ensuite stockées dans PostgreSQL.

---

## Étapes pour lancer le projet :  

1. **Configurer l'environnement Conda** :  
    ```bash
    conda create -n kafka_airflow_fasapi python=3.10
    conda activate kafka_airflow_fasapi
    conda install -c conda-forge argparse pandas
    pip install confluent-kafka joblib requests psycopg2 sqlalchemy
    ```

2. **Apache Airflow** :  
   - Initialisez la base de données :  
     ```bash
     airflow db init
     ```
   - Lancez le serveur web :  
     ```bash
     airflow webserver -p 8080
     ```
   - Lancez le scheduler :  
     ```bash
     airflow scheduler
     ```

3. **Exécuter Kafka Producer et Consumer** :  
   - Producteur :  
     ```bash
     python3 producer.py
     ```
   - Consommateur :  
     ```bash
     python3 consumer.py
     ```

---

## Flux global Kafka Confluent :
![image](https://github.com/billel0912/LEAD-Bloc1-Netflix-Recommendation-Jedha/assets/114284427/61c6c3d9-3dc4-4a77-977b-b8810176341d)

Ce flux inclut :  
- La génération de données en temps réel depuis l'API Jedha.  
- La publication des données dans des topics Kafka.  
- La consommation des données via FastAPI pour des recommandations.  
- Le stockage des résultats dans Amazon S3 et PostgreSQL.

---

## Remarque :
En raison des limitations de taille sur GitHub, les fichiers volumineux **data_cleaned.csv** et **model.pkl** ont été remplacés par des versions réduites :  
- **data_cleaned_sample.csv** et **model_sample.pkl**.  
Pour accéder aux fichiers complets, consultez les répertoires Google Drive.
```
